"""Embedding provider module for the RAG system.

This module provides a high-level embedding provider that wraps the core
OpenAIEmbeddingService with additional functionality and maintains backward compatibility.
"""

import logging
from collections.abc import Callable
from typing import TYPE_CHECKING

from langchain_core.embeddings import Embeddings

from rag.config.components import EmbeddingConfig
from rag.utils.logging_utils import log_message

from .protocols import EmbeddingServiceProtocol

if TYPE_CHECKING:
    from .embedding_service import OpenAIEmbeddingService

logger = logging.getLogger(__name__)

# Type alias for log callback function
type LogCallback = Callable[[str, str, str], None]


class EmbeddingProvider(EmbeddingServiceProtocol, Embeddings):
    """High-level embedding provider that wraps OpenAIEmbeddingService.

    This class provides a high-level interface for embedding operations
    while delegating core embedding operations to the focused OpenAIEmbeddingService.
    Implements the EmbeddingServiceProtocol for dependency injection compatibility.
    """

    def __init__(
        self,
        config: EmbeddingConfig,
        *,
        openai_api_key: str | None = None,
        show_progress_bar: bool = False,
        log_callback: LogCallback | None = None,
        embedding_service: "OpenAIEmbeddingService | None" = None,
    ) -> None:
        """Initialize the embedding provider.

        Args:
            config: Embedding configuration
            openai_api_key: OpenAI API key (optional if set in environment)
            show_progress_bar: Whether to show a progress bar for batch operations
            log_callback: Optional callback for logging
            embedding_service: Optional pre-configured OpenAIEmbeddingService instance
        """
        self.config = config
        self.model_name = config.model
        self.openai_api_key = openai_api_key  # Keep API key separate for security
        self.show_progress_bar = show_progress_bar
        self.log_callback = log_callback

        # Initialize or use provided embedding service
        if embedding_service is not None:
            self._embedding_service = embedding_service
        else:
            from .embedding_service import OpenAIEmbeddingService, RetryConfig

            # Create retry config from embedding config
            retry_config = RetryConfig(
                max_retries=self.config.max_retries,
                # Keep other retry settings as defaults for now
            )

            self._embedding_service = OpenAIEmbeddingService(
                model_name=self.model_name,
                openai_api_key=openai_api_key,
                show_progress_bar=show_progress_bar,
                log_callback=log_callback,
                retry_config=retry_config,
            )

    def _log(self, level: str, message: str) -> None:
        """Log a message.

        Args:
            level: Log level (INFO, WARNING, ERROR, etc.)
            message: The log message

        """
        log_message(level, message, "EmbeddingProvider", self.log_callback)

    @property
    def embedding_dimension(self) -> int:
        """Get the dimension of the embeddings generated by the model.

        Returns:
            Dimension of the embeddings

        """
        return self._embedding_service.embedding_dimension

    @property
    def get_embeddings_model(self) -> Embeddings:
        """Get the underlying embeddings model.

        Returns:
            The langchain embeddings model

        """
        return self._embedding_service.underlying_model

    def embed_texts(self, texts: list[str]) -> list[list[float]]:
        """Generate embeddings for a list of texts.

        Args:
            texts: List of texts to embed

        Returns:
            List of embeddings (lists of floats)

        Raises:
            ValueError, TypeError: If embedding generation fails
            RateLimitError, APIError, APIConnectionError: API errors that will be retried

        """
        self._log("DEBUG", f"Delegating embedding of {len(texts)} texts to service")
        return self._embedding_service.embed_texts(texts)

    def embed_query(self, query: str) -> list[float]:
        """Generate embedding for a query.

        Args:
            query: Query text to embed

        Returns:
            Embedding for the query

        Raises:
            ValueError, TypeError: If embedding generation fails
            RateLimitError, APIError, APIConnectionError: API errors that will be retried

        """
        self._log("DEBUG", "Delegating query embedding to service")
        return self._embedding_service.embed_query(query)

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        """Generate embeddings for a list of documents.

        Args:
            texts: List of texts to embed

        Returns:
            List of embeddings for the texts

        Raises:
            ValueError, TypeError: If embedding generation fails
            RateLimitError, APIError, APIConnectionError: API errors that will be retried

        """
        self._log("DEBUG", f"Delegating embedding of {len(texts)} documents to service")
        return self._embedding_service.embed_texts(texts)

    def get_model_info(self) -> dict[str, str]:
        """Get information about the embeddings model.

        Returns:
            Dictionary with embedding model information

        """
        return {
            "embedding_model": self.model_name,
            "model_version": self._get_model_version(),
            "embedding_dimension": str(self.embedding_dimension),
        }

    def _get_model_version(self) -> str:
        """Get the version of the embedding model.

        Returns:
            Model version string

        """
        # For OpenAI models, derive version from the model name
        if self.model_name == "text-embedding-3-small":
            return "3-small"
        if self.model_name == "text-embedding-3-large":
            return "3-large"
        if self.model_name == "text-embedding-ada-002":
            return "ada-002"
        return "unknown"

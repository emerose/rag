"""
This type stub file was generated by pyright.
"""

from typing import Any, List, Optional
from langchain_text_splitters.base import TextSplitter

class SentenceTransformersTokenTextSplitter(TextSplitter):
    """Splitting text to tokens using sentence model tokenizer."""
    def __init__(self, chunk_overlap: int = ..., model_name: str = ..., tokens_per_chunk: Optional[int] = ..., **kwargs: Any) -> None:
        """Create a new TextSplitter."""
        ...
    
    def split_text(self, text: str) -> List[str]:
        """Splits the input text into smaller components by splitting text on tokens.

        This method encodes the input text using a private `_encode` method, then
        strips the start and stop token IDs from the encoded result. It returns the
        processed segments as a list of strings.

        Args:
            text (str): The input text to be split.

        Returns:
            List[str]: A list of string components derived from the input text after
            encoding and processing.
        """
        ...
    
    def count_tokens(self, *, text: str) -> int:
        """Counts the number of tokens in the given text.

        This method encodes the input text using a private `_encode` method and
        calculates the total number of tokens in the encoded result.

        Args:
            text (str): The input text for which the token count is calculated.

        Returns:
            int: The number of tokens in the encoded text.
        """
        ...
    
    _max_length_equal_32_bit_integer: int = ...


